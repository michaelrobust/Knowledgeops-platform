import os
import json
from typing import List, Dict, Any
from .vector_service import VectorService

class LLMService:
    def __init__(self):
        """Initialize LLM service"""
        self.vector_service = VectorService()
    
    def search_relevant_documents(self, question: str, max_docs: int = 3) -> List[Dict[str, Any]]:
        """
        Search for relevant documents using vector similarity search
        """
        try:
            results = self.vector_service.search_similar(question, max_docs)
            return results
        except Exception as e:
            print(f"Vector search failed: {e}")
            return []
    
    def generate_response(self, question: str, use_rag: bool = True) -> Dict[str, Any]:
        """
        Generate response using LLM with optional RAG
        """
        try:
            if use_rag:
                # Search relevant documents
                relevant_docs = self.search_relevant_documents(question)
                
                # Combine context
                context = "\n".join([doc.get('content', '') for doc in relevant_docs])
                
                # Basic prompt template
                prompt = f"""Answer the question based on the following document content:

Document Content:
{context}

Question: {question}

Please answer based on the provided document content. If no relevant information is found in the documents, please indicate that.
"""
                
                # TODO: Integrate OpenAI/Claude API here
                # Return basic response for now
                response = {
                    "answer": f"Found {len(relevant_docs)} relevant documents. Need to integrate LLM API to generate complete answer.",
                    "sources": relevant_docs,
                    "prompt": prompt,
                    "use_rag": True
                }
            else:
                # Direct answer without RAG
                response = {
                    "answer": "This is a basic answer without RAG. Need to integrate LLM API.",
                    "sources": [],
                    "prompt": question,
                    "use_rag": False
                }
            
            return response
            
        except Exception as e:
            return {
                "error": f"Error generating response: {str(e)}",
                "answer": None,
                "sources": []
            }
    
    def process_query(self, query: str, use_rag: bool = True) -> Dict[str, Any]:
        """
        Main method to process user queries
        """
        return self.generate_response(query, use_rag)
